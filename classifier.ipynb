{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading in Data with Tensorflow and Keras\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breeds = [ \"beagle\", \"bernese_mountain_dog\", \"doberman\", \"labrador_retriever\", \"siberian_husky\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "\n",
    "args = {\n",
    "    \"labels\": \"inferred\",\n",
    "    \"label_mode\": \"categorical\", #each breed is one category\n",
    "    \"batch_size\": 32,  # 32 images are loaded and process at once\n",
    "    \"image_size\": (256, 256), # to resize all images to same size\n",
    "    \"seed\": 1,  # to ensure that the same sequence of random numbers is generated every time the model is trained / tested\n",
    "    \"validation_split\": .2,  # 20% of the data to be used to validate algorithm\n",
    "    \"class_names\": breeds \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Validation Dataset\n",
    "train = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"images\",\n",
    "    subset=\"training\",\n",
    "    **args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Test Dataset\n",
    "test = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"images\",\n",
    "    subset=\"validation\",\n",
    "    **args\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train\n",
    "# BatachDataset indicates that train data has been loaded into the tensorflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Images in Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To get the first batch (1 batch is 32 images)\n",
    "first = train.take(1)\n",
    "first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To look at images and labels in first batch\n",
    "images , labels = list(first)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = images[0]\n",
    "\n",
    "# Showing the first image [red, green, blue]\n",
    "# TF seperated 3 main colours into 3 matrixes\n",
    "first_image[:3,:3,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "Image.fromarray(first_image.numpy().astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels[0]\n",
    "\n",
    "#  numpy=array([0., 0., 0., 0., 1.], 1 located at last place indicates that this image is a husky"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an Initial Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To load everything from memory instead of the hard drive\n",
    "# For performance optimisation\n",
    "\n",
    "train = train.cache().prefetch(buffer_size= tf.data.AUTOTUNE)\n",
    "test = test.cache().prefetch(buffer_size= tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "model = Sequential([\n",
    "  tf.keras.layers.Rescaling(1./255),  # Rescale data to a form for neural network easier to work with\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu', input_shape=(256,256,3)), # Run convolutional network to scan over images\n",
    "  layers.Flatten(), # Bring features that nn has created for us to prediction\n",
    "  layers.Dense(128, activation='relu'), # To convert it to prediction layer\n",
    "  layers.Dense(len(breeds)) # Layer to make the prediction\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\", \n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True),  #defines the loss function for a categorical classification model using cross-entropy with logits.\n",
    "    metrics= [\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train,\n",
    "    validation_data = test,\n",
    "    epochs = 5,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Looking at Model Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "history_df = pd.DataFrame.from_dict(history.history)\n",
    "\n",
    "# To Display in Table Form\n",
    "#history_df[[\"accuracy\", \"val_accuracy\"]]\n",
    "\n",
    "# To Display in Graph Form\n",
    "history_df[[\"accuracy\", \"val_accuracy\"]].plot()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfitting Occured "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Model Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(network, epochs=5):\n",
    "    model = Sequential(network)\n",
    "\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(\n",
    "      train,\n",
    "      validation_data=test,\n",
    "      epochs=epochs\n",
    "    )\n",
    "    history_df = pd.DataFrame.from_dict(history.history)\n",
    "    return history_df, model\n",
    "\n",
    "   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = [\n",
    "  tf.keras.layers.Rescaling(1./255),  # Rescale data to a form for neural network easier to work with\n",
    "  layers.Conv2D(16, 4, padding='same', activation='relu', input_shape=(256,256,3)), # Increase size of window to 4\n",
    "  layers.MaxPooling2D(), # Reduce overfitting and makes model run faster by reducing the num of parameter\n",
    "  layers.Conv2D(32, 4, padding='same', activation='relu', input_shape=(256,256,3)), # Increase num of filters, let it pickup higher level features\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 4, padding='same', activation='relu', input_shape=(256,256,3)),\n",
    "  layers.MaxPooling2D(),\n",
    "\n",
    "  layers.Dropout(.2), # Randomly setting some of the output to zero\n",
    "\n",
    "  layers.Flatten(), # Bring features that nn has created for us to prediction\n",
    "  layers.Dense(128, activation='relu'), # To convert it to prediction layer\n",
    "  layers.Dense(len(breeds)) # Layer to make the prediction\n",
    "]\n",
    "\n",
    "history_df, model = train_model(network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df[[\"accuracy\", \"val_accuracy\"]].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Still Overfitting but improved result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmenting Our Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate more data for neural network\n",
    "\n",
    "data_augmentation = tf.keras.Sequential([\n",
    "\n",
    "    layers.RandomFlip(\"horizontal\", seed = 1), # Flip image left right\n",
    "    layers.RandomRotation(.2, seed = 1), # Rotate image randomly 90, 180, 270\n",
    "    layers.RandomZoom(.2, seed = 1) \n",
    "\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_network = [data_augmentation] + network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df, model = train_model(full_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df[[\"accuracy\", \"val_accuracy\"]].plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Investigating Model Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "predicted_class = np.argmax(preds, axis = 1)\n",
    "\n",
    "predicted_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_labels = np.concatenate([y for x, y in test], axis = 0)\n",
    "actual_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_class = np.argmax(actual_labels, axis = 1)\n",
    "actual_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "actual_image = [x.numpy().astype(\"uint8\") for x, y in test]\n",
    "actual_image = list(itertools.chain.from_iterable(actual_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_image = [Image.fromarray(a) for a in actual_image]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(zip(predicted_class, actual_class, actual_image), columns = [\"prediction\", \"actual\", \"image\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[\"prediction\"] = pred_df[\"prediction\"].apply(lambda x: breeds[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[\"actual\"] = pred_df[\"actual\"].apply(lambda x: breeds[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import io\n",
    "\n",
    "def image_formatter(img):\n",
    "    with io.BytesIO() as buffer:\n",
    "        img.save(buffer, 'png')\n",
    "        img_str = base64.b64encode(buffer.getvalue()).decode()\n",
    "        return f'<img src=\"data:image/jpeg;base64,{img_str}\">'\n",
    "\n",
    "pred_df.head(10).style.format({'image': image_formatter})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
